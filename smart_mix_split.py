import pandas as pd
import os
import glob
from collections import defaultdict
import numpy as np
from typing import Dict, List
import argparse

class SmartMixSplit:
    def __init__(self, input_dir: str = "input", output_dir: str = "output"):
        """
        CSV dosyalarÄ±nÄ± birleÅŸtiren ve belirtilen yÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±na gÃ¶re 
        homojen dil daÄŸÄ±lÄ±mÄ± ile Ã¶rnekleme yapan sÄ±nÄ±f.
        
        Args:
            input_dir: CSV dosyalarÄ±nÄ±n bulunduÄŸu klasÃ¶r
            output_dir: Ã‡Ä±ktÄ± dosyalarÄ±nÄ±n kaydedileceÄŸi klasÃ¶r
        """
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.combined_data = None
        
    def read_csv_files(self) -> pd.DataFrame:
        """
        Input klasÃ¶rÃ¼ndeki tÃ¼m CSV dosyalarÄ±nÄ± okur ve birleÅŸtirir.
        
        Returns:
            BirleÅŸtirilmiÅŸ DataFrame
        """
        csv_files = glob.glob(os.path.join(self.input_dir, "*.csv"))
        
        if not csv_files:
            raise FileNotFoundError(f"'{self.input_dir}' klasÃ¶rÃ¼nde CSV dosyasÄ± bulunamadÄ±!")
        
        print(f"{len(csv_files)} CSV dosyasÄ± bulundu:")
        for file in csv_files:
            print(f"  - {os.path.basename(file)}")
        
        dataframes = []
        file_stats = {}  # Her dosya iÃ§in istatistik tutalÄ±m
        
        for file in csv_files:
            try:
                df = pd.read_csv(file)
                filename = os.path.basename(file)
                print(f"'{filename}' dosyasÄ± okundu: {len(df)} satÄ±r")
                
                # Bu dosya iÃ§in boÅŸ comment istatistikleri
                if 'comment' in df.columns:
                    initial_count = len(df)
                    # BoÅŸ comment'larÄ± tespit et
                    empty_mask = (
                        df['comment'].isna() | 
                        (df['comment'].astype(str).str.strip() == '') |
                        (df['comment'].astype(str).str.strip() == 'nan')
                    )
                    empty_count = empty_mask.sum()
                    
                    if empty_count > 0:
                        # YÄ±ldÄ±z bazÄ±nda boÅŸ comment analizi
                        empty_data = df[empty_mask]
                        if 'score' in empty_data.columns:
                            score_breakdown = empty_data['score'].value_counts().sort_index().to_dict()
                        else:
                            score_breakdown = {}
                        
                        file_stats[filename] = {
                            'total': initial_count,
                            'empty': empty_count,
                            'valid': initial_count - empty_count,
                            'score_breakdown': score_breakdown
                        }
                
                dataframes.append(df)
            except Exception as e:
                print(f"HATA: '{file}' dosyasÄ± okunamadÄ±: {e}")
        
        if not dataframes:
            raise ValueError("HiÃ§bir CSV dosyasÄ± baÅŸarÄ±yla okunamadÄ±!")
        
        # TÃ¼m dataframe'leri birleÅŸtir
        combined_df = pd.concat(dataframes, ignore_index=True)
        print(f"\nToplam {len(combined_df)} satÄ±r birleÅŸtirildi.")
        
        # Gerekli sÃ¼tunlarÄ± kontrol et
        required_columns = ['profile_name', 'score', 'comment', 'language', 'contribution', 'date', 'url']
        missing_columns = [col for col in required_columns if col not in combined_df.columns]
        
        if missing_columns:
            print(f"UYARI: Eksik sÃ¼tunlar: {missing_columns}")
            print(f"Mevcut sÃ¼tunlar: {list(combined_df.columns)}")
        
        # BoÅŸ comment'larÄ± filtrele ve detaylÄ± rapor ver
        if 'comment' in combined_df.columns:
            initial_count = len(combined_df)
            
            # Filtrelenmeden Ã¶nce yÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±nÄ± kaydet
            if 'score' in combined_df.columns:
                original_score_dist = combined_df['score'].value_counts().sort_index().to_dict()
            
            # BoÅŸ comment'larÄ± tespit et
            empty_mask = (
                combined_df['comment'].isna() | 
                (combined_df['comment'].astype(str).str.strip() == '') |
                (combined_df['comment'].astype(str).str.strip() == 'nan')
            )
            
            if empty_mask.sum() > 0:
                # BoÅŸ comment'larÄ±n yÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±
                empty_data = combined_df[empty_mask]
                if 'score' in empty_data.columns:
                    empty_score_breakdown = empty_data['score'].value_counts().sort_index().to_dict()
                else:
                    empty_score_breakdown = {}
                
                # BoÅŸ olmayan veriyi filtrele
                combined_df = combined_df[~empty_mask]
                filtered_count = len(combined_df)
                removed_count = initial_count - filtered_count
                
                print(f"\n{'='*60}")
                print("BOÅ COMMENT FÄ°LTRELEME RAPORU")
                print(f"{'='*60}")
                
                # Dosya bazÄ±nda rapor
                total_empty_files = 0
                for filename, stats in file_stats.items():
                    if stats['empty'] > 0:
                        total_empty_files += 1
                        percentage = (stats['empty'] / stats['total']) * 100
                        print(f"\nğŸ“ {filename}:")
                        print(f"  â€¢ Toplam satÄ±r: {stats['total']}")
                        print(f"  â€¢ BoÅŸ comment: {stats['empty']} ({percentage:.1f}%)")
                        print(f"  â€¢ GeÃ§erli satÄ±r: {stats['valid']}")
                        
                        if stats['score_breakdown']:
                            print(f"  â€¢ YÄ±ldÄ±z bazÄ±nda boÅŸ comment daÄŸÄ±lÄ±mÄ±:")
                            for score, count in sorted(stats['score_breakdown'].items()):
                                print(f"    - {score} yÄ±ldÄ±z: {count} boÅŸ comment")
                
                if total_empty_files == 0:
                    print("\nâœ… HiÃ§bir dosyada boÅŸ comment bulunamadÄ±!")
                else:
                    print(f"\nğŸ“Š GENEL Ã–ZET:")
                    print(f"  â€¢ BoÅŸ comment iÃ§eren dosya sayÄ±sÄ±: {total_empty_files}")
                    print(f"  â€¢ Toplam filtrelenen boÅŸ comment: {removed_count}")
                    print(f"  â€¢ Kalan geÃ§erli yorum: {filtered_count}")
                    
                    if empty_score_breakdown:
                        print(f"\nâ­ TOPLAM YILDIZ BAZINDA BOÅ COMMENT DAÄILIMI:")
                        for score in sorted(empty_score_breakdown.keys()):
                            count = empty_score_breakdown[score]
                            total_for_score = original_score_dist.get(score, 0)
                            if total_for_score > 0:
                                percentage = (count / total_for_score) * 100
                                print(f"  â€¢ {score} yÄ±ldÄ±z: {count} boÅŸ comment (toplam {score} yÄ±ldÄ±zlÄ±nÄ±n %{percentage:.1f}'i)")
                            else:
                                print(f"  â€¢ {score} yÄ±ldÄ±z: {count} boÅŸ comment")
                
                print(f"{'='*60}")
            else:
                print(f"\nâœ… HiÃ§bir boÅŸ comment bulunamadÄ±! TÃ¼m {initial_count} satÄ±r geÃ§erli.")
        
        self.combined_data = combined_df
        return combined_df
    
    def analyze_data(self) -> Dict:
        """
        Veriyi analiz eder ve istatistikleri dÃ¶ndÃ¼rÃ¼r.
        
        Returns:
            Analiz sonuÃ§larÄ±
        """
        if self.combined_data is None:
            raise ValueError("Ã–nce CSV dosyalarÄ±nÄ± okuyun!")
        
        df = self.combined_data
        
        analysis = {
            'total_rows': len(df),
            'unique_airports': df['profile_name'].nunique() if 'profile_name' in df.columns else 0,
            'score_distribution': df['score'].value_counts().sort_index().to_dict() if 'score' in df.columns else {},
            'language_distribution': df['language'].value_counts().to_dict() if 'language' in df.columns else {},
            'airports': df['profile_name'].value_counts().to_dict() if 'profile_name' in df.columns else {}
        }
        
        return analysis
    
    def print_analysis(self, analysis: Dict):
        """
        Analiz sonuÃ§larÄ±nÄ± yazdÄ±rÄ±r.
        """
        print("\n" + "="*50)
        print("VERÄ° ANALÄ°ZÄ°")
        print("="*50)
        print(f"Toplam satÄ±r sayÄ±sÄ±: {analysis['total_rows']}")
        print(f"Benzersiz havalimanÄ± sayÄ±sÄ±: {analysis['unique_airports']}")
        
        print(f"\nYÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±:")
        for score, count in sorted(analysis['score_distribution'].items()):
            percentage = (count / analysis['total_rows']) * 100
            print(f"  {score} yÄ±ldÄ±z: {count} ({percentage:.1f}%)")
        
        print(f"\nDil daÄŸÄ±lÄ±mÄ±:")
        for lang, count in sorted(analysis['language_distribution'].items(), key=lambda x: x[1], reverse=True):
            percentage = (count / analysis['total_rows']) * 100
            print(f"  {lang}: {count} ({percentage:.1f}%)")
        
        print(f"\nHavalimanÄ± daÄŸÄ±lÄ±mÄ±:")
        for airport, count in sorted(analysis['airports'].items(), key=lambda x: x[1], reverse=True)[:10]:
            percentage = (count / analysis['total_rows']) * 100
            print(f"  {airport}: {count} ({percentage:.1f}%)")
        if len(analysis['airports']) > 10:
            print(f"  ... ve {len(analysis['airports']) - 10} havalimanÄ± daha")
    
    def create_balanced_sample(self, star_distribution: Dict[int, int]) -> pd.DataFrame:
        """
        Belirtilen yÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±na gÃ¶re homojen dil daÄŸÄ±lÄ±mÄ± ile Ã¶rnekleme yapar.
        
        Args:
            star_distribution: {yÄ±ldÄ±z_sayÄ±sÄ±: kaÃ§_tane_alÄ±nacak} formatÄ±nda dict
            
        Returns:
            Ã–rneklenmiÅŸ DataFrame
        """
        if self.combined_data is None:
            raise ValueError("Ã–nce CSV dosyalarÄ±nÄ± okuyun!")
        
        df = self.combined_data.copy()
        
        # BoÅŸ deÄŸerleri ve boÅŸ comment'larÄ± temizle
        df = df.dropna(subset=['score', 'language', 'profile_name'])
        
        # Comment kontrolÃ¼ - boÅŸ comment'larÄ± filtrele
        if 'comment' in df.columns:
            initial_count = len(df)
            df = df[
                df['comment'].notna() & 
                (df['comment'].astype(str).str.strip() != '') &
                (df['comment'].astype(str).str.strip() != 'nan')
            ]
            filtered_count = len(df)
            removed_count = initial_count - filtered_count
            if removed_count > 0:
                print(f"Ã–rnekleme sÄ±rasÄ±nda {removed_count} boÅŸ comment iÃ§eren satÄ±r daha filtrelendi.")
        
        # Score'u integer'a Ã§evir
        df['score'] = df['score'].astype(int)
        
        sampled_data = []
        
        print("\n" + "="*50)
        print("Ã–RNEKLEME Ä°ÅLEMÄ°")
        print("="*50)
        
        for star_rating, target_count in star_distribution.items():
            print(f"\n{star_rating} yÄ±ldÄ±zlÄ± yorumlar iÃ§in {target_count} adet seÃ§iliyor...")
            
            # Bu yÄ±ldÄ±z puanÄ±na sahip tÃ¼m yorumlarÄ± filtrele
            star_data = df[df['score'] == star_rating].copy()
            
            if len(star_data) == 0:
                print(f"  UYARI: {star_rating} yÄ±ldÄ±zlÄ± hiÃ§ yorum bulunamadÄ±!")
                continue
            
            if len(star_data) < target_count:
                print(f"  UYARI: {star_rating} yÄ±ldÄ±zlÄ± sadece {len(star_data)} yorum var, {target_count} istendi!")
                sampled_data.append(star_data)
                continue
            
            # Dil ve havalimanÄ± daÄŸÄ±lÄ±mÄ±nÄ± hesapla
            language_counts = star_data['language'].value_counts()
            airport_counts = star_data['profile_name'].value_counts()
            
            print(f"  Mevcut {star_rating} yÄ±ldÄ±zlÄ± yorum sayÄ±sÄ±: {len(star_data)}")
            print(f"  Dil sayÄ±sÄ±: {len(language_counts)}")
            print(f"  HavalimanÄ± sayÄ±sÄ±: {len(airport_counts)}")
            
            # Homojen daÄŸÄ±lÄ±m iÃ§in her dilden ve havalimanÄ±ndan proportional olarak al
            selected_indices = []
            
            # Her dil iÃ§in orantÄ±lÄ± Ã¶rnekleme
            for language in language_counts.index:
                lang_data = star_data[star_data['language'] == language]
                lang_proportion = len(lang_data) / len(star_data)
                lang_target = max(1, int(target_count * lang_proportion))
                
                # Her havalimanÄ±ndan da orantÄ±lÄ± al
                lang_selected = []
                airport_counts_in_lang = lang_data['profile_name'].value_counts()
                
                for airport in airport_counts_in_lang.index:
                    airport_data = lang_data[lang_data['profile_name'] == airport]
                    airport_proportion = len(airport_data) / len(lang_data)
                    airport_target = max(1, int(lang_target * airport_proportion))
                    airport_target = min(airport_target, len(airport_data))
                    
                    if airport_target > 0:
                        selected = airport_data.sample(n=airport_target, random_state=42)
                        lang_selected.extend(selected.index.tolist())
                
                # EÄŸer yeterli seÃ§ilmediyse, kalan kÄ±smÄ± rastgele ekle
                remaining_needed = lang_target - len(lang_selected)
                if remaining_needed > 0:
                    available_indices = set(lang_data.index) - set(lang_selected)
                    if available_indices:
                        additional = min(remaining_needed, len(available_indices))
                        additional_indices = np.random.choice(
                            list(available_indices), 
                            size=additional, 
                            replace=False
                        )
                        lang_selected.extend(additional_indices.tolist())
                
                selected_indices.extend(lang_selected)
            
            # Hedef sayÄ±ya ulaÅŸmak iÃ§in eksik olanlarÄ± rastgele ekle
            if len(selected_indices) < target_count:
                remaining_needed = target_count - len(selected_indices)
                available_indices = set(star_data.index) - set(selected_indices)
                if available_indices:
                    additional = min(remaining_needed, len(available_indices))
                    additional_indices = np.random.choice(
                        list(available_indices), 
                        size=additional, 
                        replace=False
                    )
                    selected_indices.extend(additional_indices.tolist())
            
            # Hedef sayÄ±yÄ± aÅŸtÄ±ysak rastgele azalt
            if len(selected_indices) > target_count:
                selected_indices = np.random.choice(
                    selected_indices, 
                    size=target_count, 
                    replace=False
                ).tolist()
            
            selected_sample = star_data.loc[selected_indices]
            sampled_data.append(selected_sample)
            
            print(f"  SeÃ§ilen yorum sayÄ±sÄ±: {len(selected_sample)}")
            
            # SeÃ§ilen Ã¶rnekteki dil daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶ster
            sample_lang_dist = selected_sample['language'].value_counts()
            print(f"  SeÃ§ilen Ã¶rnekteki dil daÄŸÄ±lÄ±mÄ±:")
            for lang, count in sample_lang_dist.items():
                percentage = (count / len(selected_sample)) * 100
                print(f"    {lang}: {count} ({percentage:.1f}%)")
        
        # TÃ¼m Ã¶rnekleri birleÅŸtir
        if sampled_data:
            final_sample = pd.concat(sampled_data, ignore_index=True)
            
            # KarÄ±ÅŸtÄ±r
            final_sample = final_sample.sample(frac=1, random_state=42).reset_index(drop=True)
            
            print(f"\nToplam Ã¶rneklenen yorum sayÄ±sÄ±: {len(final_sample)}")
            return final_sample
        else:
            print("HATA: HiÃ§bir Ã¶rnekleme yapÄ±lamadÄ±!")
            return pd.DataFrame()
    
    def save_results(self, sampled_data: pd.DataFrame, filename: str = "sampled_data.csv"):
        """
        Ã–rneklenen veriyi CSV dosyasÄ± olarak kaydeder.
        
        Args:
            sampled_data: Ã–rneklenen DataFrame
            filename: Ã‡Ä±ktÄ± dosyasÄ± adÄ±
        """
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        output_path = os.path.join(self.output_dir, filename)
        sampled_data.to_csv(output_path, index=False)
        print(f"\nSonuÃ§lar '{output_path}' dosyasÄ±na kaydedildi.")
        
        # Ã–zet istatistikleri de kaydet
        summary_path = os.path.join(self.output_dir, "summary.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("Ã–RNEKLEME Ã–ZETÄ°\n")
            f.write("="*50 + "\n")
            f.write(f"Toplam Ã¶rneklenen satÄ±r: {len(sampled_data)}\n\n")
            
            f.write("YÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±:\n")
            score_dist = sampled_data['score'].value_counts().sort_index()
            for score, count in score_dist.items():
                percentage = (count / len(sampled_data)) * 100
                f.write(f"  {score} yÄ±ldÄ±z: {count} ({percentage:.1f}%)\n")
            
            f.write("\nDil daÄŸÄ±lÄ±mÄ±:\n")
            lang_dist = sampled_data['language'].value_counts()
            for lang, count in lang_dist.items():
                percentage = (count / len(sampled_data)) * 100
                f.write(f"  {lang}: {count} ({percentage:.1f}%)\n")
            
            f.write("\nHavalimanÄ± daÄŸÄ±lÄ±mÄ±:\n")
            airport_dist = sampled_data['profile_name'].value_counts()
            for airport, count in airport_dist.items():
                percentage = (count / len(sampled_data)) * 100
                f.write(f"  {airport}: {count} ({percentage:.1f}%)\n")
        
        print(f"Ã–zet istatistikler '{summary_path}' dosyasÄ±na kaydedildi.")


def main():
    """
    Ana fonksiyon - programÄ± Ã§alÄ±ÅŸtÄ±rÄ±r.
    """
    # Komut satÄ±rÄ± argÃ¼manlarÄ±
    parser = argparse.ArgumentParser(description='HavalimanÄ± yorumlarÄ±nÄ± karÄ±ÅŸtÄ±rÄ±p Ã¶rnekleyen program')
    parser.add_argument('--input-dir', default='input', help='CSV dosyalarÄ±nÄ±n bulunduÄŸu klasÃ¶r')
    parser.add_argument('--output-dir', default='output', help='Ã‡Ä±ktÄ± dosyalarÄ±nÄ±n kaydedileceÄŸi klasÃ¶r')
    
    args = parser.parse_args()
    
    # SmartMixSplit nesnesini oluÅŸtur
    mixer = SmartMixSplit(args.input_dir, args.output_dir)
    
    try:
        # CSV dosyalarÄ±nÄ± oku ve birleÅŸtir
        print("CSV dosyalarÄ± okunuyor...")
        combined_data = mixer.read_csv_files()
        
        # Veriyi analiz et
        analysis = mixer.analyze_data()
        mixer.print_analysis(analysis)
        
        # KullanÄ±cÄ±dan yÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±nÄ± al
        print("\n" + "="*50)
        print("YILDIZ DAÄILIMI BELÄ°RLEME")
        print("="*50)
        print("Her yÄ±ldÄ±z puanÄ±ndan kaÃ§ adet yorum alÄ±nacaÄŸÄ±nÄ± belirtin:")
        print("(0 girmeyin eÄŸer o yÄ±ldÄ±zdan hiÃ§ almak istemiyorsanÄ±z)")
        
        star_distribution = {}
        for star in [5, 4, 3, 2, 1]:
            while True:
                try:
                    available = analysis['score_distribution'].get(star, 0)
                    count = input(f"{star} yÄ±ldÄ±zlÄ± yorumlar (mevcut: {available}): ").strip()
                    if count == "":
                        continue
                    count = int(count)
                    if count < 0:
                        print("Negatif sayÄ± giremezsiniz!")
                        continue
                    if count > available:
                        print(f"Mevcut {star} yÄ±ldÄ±zlÄ± yorum sayÄ±sÄ± ({available}) aÅŸtÄ±nÄ±z!")
                        continue
                    if count > 0:
                        star_distribution[star] = count
                    break
                except ValueError:
                    print("LÃ¼tfen geÃ§erli bir sayÄ± girin!")
        
        if not star_distribution:
            print("HiÃ§bir yÄ±ldÄ±z puanÄ± seÃ§ilmedi! Program sonlandÄ±rÄ±lÄ±yor.")
            return
        
        print(f"\nSeÃ§ilen daÄŸÄ±lÄ±m: {star_distribution}")
        total_target = sum(star_distribution.values())
        print(f"Toplam hedef: {total_target} yorum")
        
        # Ã–rnekleme yap
        sampled_data = mixer.create_balanced_sample(star_distribution)
        
        if len(sampled_data) == 0:
            print("HATA: Ã–rnekleme iÅŸlemi baÅŸarÄ±sÄ±z!")
            return
        
        # SonuÃ§larÄ± kaydet
        mixer.save_results(sampled_data)
        
        print("\n" + "="*50)
        print("Ä°ÅLEM TAMAMLANDI!")
        print("="*50)
        print(f"Toplam {len(sampled_data)} yorum baÅŸarÄ±yla Ã¶rneklendi ve kaydedildi.")
        
    except Exception as e:
        print(f"\nHATA: {e}")
        return


if __name__ == "__main__":
    main()
